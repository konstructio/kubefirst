apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: vault
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  annotations:
    argocd.argoproj.io/sync-wave: "6"
spec:
  destination:
    server: https://kubernetes.default.svc
    namespace: vault
  project: default
  source:
    repoURL: 'https://helm.releases.hashicorp.com'
    targetRevision: 0.18.0
    helm:
      parameters:
        - name: server.route.host
          value: vault.<AWS_HOSTED_ZONE_NAME>
        - name: 'server.ingress.hosts[0].host'
          value: vault.<AWS_HOSTED_ZONE_NAME>
      values: |-
        server:
          image:
            repository: "vault"
            tag: "1.9.2"
          affinity: ""
          ha:
            enabled: true
            replicas: 3
           
            # config is a raw string of default configuration when using a Stateful
            # deployment. Default is to use a Consul for its HA storage backend.
            # This should be HCL.
            
            # Note: Configuration files are stored in ConfigMaps so sensitive data 
            # such as passwords should be either mounted through extraSecretEnvironmentVars
            # or through a Kube secret.  For more information see: 
            # https://www.vaultproject.io/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
            config: |
              ui = true
        
              listener "tcp" {
                tls_disable = 1
                address = "[::]:8200"
                cluster_address = "[::]:8201"
              }
        
              storage "dynamodb" {
                ha_enabled = "true"
                region = "<AWS_DEFAULT_REGION>"
                table = "vault-dynamodb-backend"
              }
        
              seal "awskms" {
                 region     = "<AWS_DEFAULT_REGION>"
                 kms_key_id = "<KMS_KEY_ID>"
              }
              service_registration "kubernetes" {}
        
          ui:
            enabled: true
            serviceType: "ClusterIP"
            serviceNodePort: null
            externalPort: 8200
          ingress:
            enabled: true
            annotations:
              kubernetes.io/ingress.class: nginx
              cert-manager.io/cluster-issuer: "letsencrypt-prod"
            path: /
            host: vault.<AWS_HOSTED_ZONE_NAME>
            tls:
             - secretName: vault-tls
               hosts:
                 - vault.<AWS_HOSTED_ZONE_NAME>
        injector:
          enabled: true
    chart: vault
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    # todo blue - mutating webhooks needs to be ignored in argocd
    syncOptions:
      - CreateNamespace=true
---
apiVersion: batch/v1
kind: Job
metadata:
  name: unseal-vault
  annotations:
    argocd.argoproj.io/sync-wave: "6"
    # argocd.argoproj.io/hook: PostSync # don't PostSync, vault doesn't finish sync while waiting for pods to be running which requires this job
    # argocd.argoproj.io/hook-delete-policy: HookSucceeded
spec:
  template:
    spec:
      containers:
        # todo adjust node permissions to be adequate for geting a kubeconfig in terraform - manually adding in console
      - name: unseal-vault
        image: kubefirst/kubefirst-builder:spike # TODO: official versioned image
        command:
        - /bin/bash
        - -c
        - |
          sleep 30
          aws eks update-kubeconfig --name kubefirst --region <AWS_DEFAULT_REGION>
          kubectl -n vault exec vault-0 -- vault operator init -format=json > cluster-keys.json
          kubectl -n vault create secret generic vault-unseal-keys --from-file=cluster-keys.json
        # todo remove this envFrom and assume role
        envFrom:
        - secretRef:
            name: aws-creds
      restartPolicy: Never
  backoffLimit: 2